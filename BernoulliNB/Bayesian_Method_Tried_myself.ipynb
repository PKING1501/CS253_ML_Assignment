{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Step 1: Data Preprocessing\n",
        "data = pd.read_csv('train.csv')\n",
        "data1 = pd.read_csv('test.csv')\n",
        "data.drop(columns=['ID','Candidate','Constituency ∇'], inplace=True)\n",
        "data1.drop(columns=['ID','Candidate','Constituency ∇'], inplace=True)\n",
        "\n",
        "def convert_to_lakhs(value):\n",
        "    value = str(value)\n",
        "    if value == \"0\":\n",
        "        return 0\n",
        "    elif 'Crore+' in value:\n",
        "        number, unit = value.split()\n",
        "        number = float(number.replace(\",\", \"\"))\n",
        "        return int(number * 100)\n",
        "    elif 'Lac+' in value:\n",
        "        number, unit = value.split()\n",
        "        number = float(number.replace(\",\", \"\"))\n",
        "        return int(number)\n",
        "    elif 'Thou+' in value:\n",
        "        number, unit = value.split()\n",
        "        number = float(number.replace(\",\", \"\"))\n",
        "        return int(number / 100)\n",
        "    elif 'Hund+' in value:\n",
        "        number, unit = value.split()\n",
        "        number = float(number.replace(\",\", \"\"))\n",
        "        return int(number / 1000)\n",
        "    else:\n",
        "        return int(value)\n",
        "\n",
        "data[\"Total Assets\"] = data[\"Total Assets\"].apply(convert_to_lakhs)\n",
        "data[\"Liabilities\"] = data[\"Liabilities\"].apply(convert_to_lakhs)\n",
        "data1[\"Total Assets\"] = data1[\"Total Assets\"].apply(convert_to_lakhs)\n",
        "data1[\"Liabilities\"] = data1[\"Liabilities\"].apply(convert_to_lakhs)\n",
        "\n",
        "# Perform label encoding for Education column\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "data['Education'] = label_encoder.fit_transform(data['Education'])\n",
        "\n",
        "# data['Education'] = data['Education'].astype('category').cat.codes\n",
        "X = data.drop(columns=['Education'])\n",
        "y = data['Education']\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# y_check = label_encoder.inverse_transform(y_test)\n",
        "\n",
        "label_relative_frequencies = []\n",
        "total_train_rows = len(X)\n",
        "\n",
        "# Iterate through each label\n",
        "for label in range(10):\n",
        "    label_dataset_rows = (y == label).sum()\n",
        "    label_relative_frequency = label_dataset_rows / total_train_rows\n",
        "    label_relative_frequencies.append(label_relative_frequency)\n",
        "\n",
        "# print(label_relative_frequencies)\n",
        "\n",
        "y = pd.get_dummies(y, columns=['Education'])\n",
        "X = pd.get_dummies(X, columns=['Party','state'])\n",
        "# X_train.drop(columns=['Party_CPI','Party_TDP','Party_Tipra Motha Party'],inplace=True)\n",
        "data1 = pd.get_dummies(data1, columns=['Party','state'])\n",
        "# data1 = pd.get_dummies(data1, columns=['Party','state'])\n",
        "\n",
        "# Step 3: Train a Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier( n_estimators=91, max_depth=25, max_features='log2', min_samples_split=7, min_samples_leaf=1, random_state=42)\n",
        "rf_classifier.fit(X, y)\n",
        "\n",
        "predictions = []\n",
        "for i in range(len(data1)):\n",
        "    y_pred_proba = rf_classifier.predict_proba(data1.iloc[[i]])\n",
        "    result_list = [(arr[0][1] * label_relative_frequencies[i]) for i, arr in enumerate(y_pred_proba)]\n",
        "    max_index = result_list.index(max(result_list))\n",
        "    predictions.append(max_index)\n",
        "\n",
        "\n",
        "predictions = label_encoder.inverse_transform(predictions)\n",
        "# print(predictions)\n",
        "\n",
        "# f1 = f1_score(y_check, predictions, average='weighted')\n",
        "# print(\"F1 Score:\", f1)\n",
        "df_pred = pd.DataFrame(predictions, columns=[\"Education\"])\n",
        "df_pred.to_csv('submission.csv', index_label='ID')\n"
      ],
      "metadata": {
        "id": "vsa4AbtcK27n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Step 1: Data Preprocessing\n",
        "data = pd.read_csv('train.csv')\n",
        "data1 = pd.read_csv('test.csv')\n",
        "data.drop(columns=['ID','Candidate','Constituency ∇'], inplace=True)\n",
        "data1.drop(columns=['ID','Candidate','Constituency ∇'], inplace=True)\n",
        "\n",
        "def convert_to_lakhs(value):\n",
        "    value = str(value)\n",
        "    if value == \"0\":\n",
        "        return 0\n",
        "    elif 'Crore+' in value:\n",
        "        number, unit = value.split()\n",
        "        number = float(number.replace(\",\", \"\"))\n",
        "        return int(number * 100)\n",
        "    elif 'Lac+' in value:\n",
        "        number, unit = value.split()\n",
        "        number = float(number.replace(\",\", \"\"))\n",
        "        return int(number)\n",
        "    elif 'Thou+' in value:\n",
        "        number, unit = value.split()\n",
        "        number = float(number.replace(\",\", \"\"))\n",
        "        return int(number / 100)\n",
        "    elif 'Hund+' in value:\n",
        "        number, unit = value.split()\n",
        "        number = float(number.replace(\",\", \"\"))\n",
        "        return int(number / 1000)\n",
        "    else:\n",
        "        return int(value)\n",
        "\n",
        "data[\"Total Assets\"] = data[\"Total Assets\"].apply(convert_to_lakhs)\n",
        "data[\"Liabilities\"] = data[\"Liabilities\"].apply(convert_to_lakhs)\n",
        "data1[\"Total Assets\"] = data1[\"Total Assets\"].apply(convert_to_lakhs)\n",
        "data1[\"Liabilities\"] = data1[\"Liabilities\"].apply(convert_to_lakhs)\n",
        "\n",
        "# Perform label encoding for Education column\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "data['Education'] = label_encoder.fit_transform(data['Education'])\n",
        "\n",
        "label_relative_frequencies = []\n",
        "total_train_rows = len(data)\n",
        "\n",
        "# Iterate through each label\n",
        "for label in range(10):\n",
        "    label_dataset_rows = (data['Education'] == label).sum()\n",
        "    label_relative_frequency = label_dataset_rows / total_train_rows\n",
        "    label_relative_frequencies.append(label_relative_frequency)\n",
        "\n",
        "print(label_relative_frequencies)\n",
        "\n",
        "# data['Education'] = data['Education'].astype('category').cat.codes\n",
        "\n",
        "data = pd.get_dummies(data, columns=['Party','state','Education'])\n",
        "# data1 = pd.get_dummies(data1, columns=['Party','state'])\n",
        "\n",
        "\n",
        "X = data.drop(columns=['Education_0', 'Education_1', 'Education_2', 'Education_3', 'Education_4', 'Education_5', 'Education_6', 'Education_7', 'Education_8', 'Education_9'])\n",
        "y = data[['Education_0', 'Education_1', 'Education_2', 'Education_3', 'Education_4', 'Education_5', 'Education_6', 'Education_7', 'Education_8', 'Education_9']]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 3: Train a Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier.fit(X_train, y_train)\n",
        "predictions = []\n",
        "for i in range(len(X_test)):\n",
        "    y_pred_proba = rf_classifier.predict_proba(X_test.iloc[[i]])\n",
        "    result_list = [(arr[0][1] * label_relative_frequencies[i]) for i, arr in enumerate(y_pred_proba)]\n",
        "    max_index = result_list.index(max(result_list))\n",
        "    predictions.append(max_index)\n",
        "\n",
        "\n",
        "predictions = label_encoder.inverse_transform(predictions)\n",
        "print(predictions)\n",
        "\n",
        "# Print the original labels\n",
        "# Step 4: Multiply predicted probabilities with occurrence probabilities of each label in the training dataset\n",
        "# Calculate occurrence probabilities\n",
        "# label_occurrence_probabilities = y_train.mean()\n",
        "\n",
        "# # Multiply predicted probabilities with occurrence probabilities\n",
        "# probability_products = y_pred_proba * label_occurrence_probabilities.values\n",
        "\n",
        "# # Step 5: Create a DataFrame to store the probabilities\n",
        "# labels = ['Education_0', 'Education_1', 'Education_2', 'Education_3', 'Education_4',\n",
        "#           'Education_5', 'Education_6', 'Education_7', 'Education_8', 'Education_9']\n",
        "\n",
        "# prob_df = pd.DataFrame(data=probability_products, columns=labels)\n",
        "\n",
        "# # Step 6: Print the DataFrame showing the probability of each row of the test data for each label\n",
        "# print(prob_df)\n",
        "\n",
        "# X = data.drop(columns=['Education'])\n",
        "# y = data['Education']\n",
        "\n",
        "# # Split data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# scaler = StandardScaler()\n",
        "# X_train = scaler.fit_transform(X_train)\n",
        "# X_test = scaler.transform(X_test)\n",
        "\n",
        "# # n_components = 30  # Specify the number of principal components\n",
        "# # pca = PCA(n_components=n_components)\n",
        "# # X_train = pca.fit_transform(X_train)\n",
        "# # X_test = pca.transform(X_test)\n",
        "\n",
        "# # Step 2: Training the Random Forest Classifier\n",
        "# rf_classifier = RandomForestClassifier(n_estimators=86,\n",
        "#                                         criterion='gini',\n",
        "#                                         max_depth=26,\n",
        "#                                         min_samples_split=2,\n",
        "#                                         max_features='log2',\n",
        "#                                         random_state=42)\n",
        "# rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# # Step 3: Model Evaluation\n",
        "# y_pred = rf_classifier.predict(X_test)\n",
        "# f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "# print(\"F1 Score:\", f1)\n",
        "# y_pred = label_encoder.inverse_transform(y_pred)\n",
        "# Step 4: Data Visualization - Plotting code goes here\n",
        "\n",
        "# Step 5: Generate LaTeX Report - Details about the model, hyperparameters, evaluation metrics, and data visualization results.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaa-cBCIep83",
        "outputId": "601ab65a-62d0-4077-989e-b12e39a05e3a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.11024769305488101, 0.1694997571636717, 0.004371053909664886, 0.03788246721709568, 0.02525497814473045, 0.2578921806702283, 0.16464303059737737, 0.006799417192812044, 0.013598834385624089, 0.20981058766391453]\n",
            "['Post Graduate' '12th Pass' '12th Pass' 'Post Graduate' '12th Pass'\n",
            " 'Post Graduate' 'Graduate' 'Graduate' 'Graduate' 'Graduate' 'Graduate'\n",
            " 'Graduate' 'Graduate Professional' 'Graduate' '12th Pass' 'Graduate'\n",
            " 'Graduate Professional' '12th Pass' 'Graduate' '12th Pass' 'Graduate'\n",
            " 'Graduate' 'Post Graduate' 'Post Graduate' 'Graduate' 'Graduate'\n",
            " 'Graduate' 'Graduate' 'Graduate' 'Post Graduate' 'Graduate Professional'\n",
            " '10th Pass' 'Graduate' 'Graduate' '12th Pass' '12th Pass' 'Graduate'\n",
            " 'Post Graduate' 'Graduate' 'Graduate' 'Graduate' 'Graduate Professional'\n",
            " '12th Pass' 'Graduate Professional' 'Post Graduate' '10th Pass'\n",
            " 'Graduate' '12th Pass' 'Post Graduate' '12th Pass' 'Graduate' 'Graduate'\n",
            " 'Post Graduate' 'Post Graduate' 'Graduate' 'Graduate' '12th Pass'\n",
            " 'Graduate' '10th Pass' 'Graduate' 'Graduate' 'Post Graduate'\n",
            " 'Post Graduate' 'Graduate Professional' 'Post Graduate'\n",
            " 'Graduate Professional' 'Graduate Professional' 'Graduate' 'Graduate'\n",
            " 'Post Graduate' 'Graduate' 'Graduate Professional' 'Graduate' 'Graduate'\n",
            " 'Graduate' '10th Pass' 'Graduate' 'Post Graduate' 'Graduate'\n",
            " 'Post Graduate' '12th Pass' 'Graduate' 'Post Graduate' 'Post Graduate'\n",
            " 'Post Graduate' 'Graduate' 'Graduate Professional'\n",
            " 'Graduate Professional' 'Post Graduate' 'Post Graduate' 'Graduate'\n",
            " 'Graduate' 'Graduate' 'Post Graduate' 'Graduate' 'Graduate Professional'\n",
            " 'Graduate' 'Graduate' '12th Pass' '12th Pass' 'Graduate' 'Graduate'\n",
            " '12th Pass' 'Graduate' 'Post Graduate' 'Post Graduate' 'Graduate'\n",
            " '10th Pass' 'Graduate' 'Post Graduate' 'Graduate' 'Graduate'\n",
            " 'Post Graduate' 'Graduate Professional' 'Graduate Professional'\n",
            " 'Graduate' '12th Pass' 'Graduate Professional' 'Graduate' 'Post Graduate'\n",
            " 'Graduate' 'Post Graduate' 'Graduate' 'Post Graduate' '12th Pass'\n",
            " '10th Pass' 'Graduate' 'Graduate' '10th Pass' 'Post Graduate' 'Graduate'\n",
            " 'Post Graduate' 'Graduate' 'Graduate' 'Graduate' 'Graduate'\n",
            " 'Post Graduate' 'Graduate' 'Graduate' 'Post Graduate' 'Graduate'\n",
            " 'Graduate Professional' 'Post Graduate' 'Graduate' 'Post Graduate'\n",
            " '12th Pass' 'Graduate' '12th Pass' 'Graduate' 'Post Graduate'\n",
            " 'Graduate Professional' 'Post Graduate' 'Graduate Professional'\n",
            " 'Graduate Professional' 'Graduate' 'Graduate' 'Graduate Professional'\n",
            " 'Post Graduate' '12th Pass' 'Graduate' 'Graduate Professional'\n",
            " 'Post Graduate' 'Graduate' 'Graduate' 'Post Graduate' 'Graduate'\n",
            " '12th Pass' '12th Pass' 'Graduate Professional' 'Graduate' 'Graduate'\n",
            " 'Graduate Professional' 'Post Graduate' '12th Pass' 'Graduate'\n",
            " '12th Pass' '12th Pass' 'Graduate' 'Post Graduate' 'Post Graduate'\n",
            " 'Graduate' 'Graduate' 'Graduate' 'Graduate' '12th Pass' 'Graduate'\n",
            " '12th Pass' 'Post Graduate' 'Graduate' 'Graduate Professional'\n",
            " 'Post Graduate' 'Graduate Professional' 'Graduate' 'Graduate' 'Graduate'\n",
            " 'Post Graduate' 'Graduate' 'Graduate' 'Graduate' 'Graduate Professional'\n",
            " 'Graduate' 'Graduate Professional' 'Post Graduate' 'Graduate'\n",
            " 'Graduate Professional' 'Graduate' 'Graduate' 'Post Graduate' '12th Pass'\n",
            " 'Graduate' 'Graduate Professional' 'Graduate' 'Post Graduate'\n",
            " 'Post Graduate' 'Graduate' 'Graduate' '12th Pass' 'Graduate' 'Graduate'\n",
            " 'Post Graduate' 'Graduate' '12th Pass' 'Post Graduate' 'Post Graduate'\n",
            " 'Post Graduate' 'Graduate' 'Graduate' 'Graduate' 'Graduate'\n",
            " 'Post Graduate' '12th Pass' '12th Pass' 'Graduate' 'Graduate'\n",
            " 'Post Graduate' '12th Pass' 'Post Graduate' 'Graduate' 'Post Graduate'\n",
            " 'Graduate Professional' 'Graduate' 'Graduate' 'Graduate Professional'\n",
            " 'Graduate' 'Post Graduate' 'Graduate' 'Post Graduate' 'Graduate'\n",
            " 'Graduate' 'Graduate' 'Graduate' 'Post Graduate' 'Graduate' '12th Pass'\n",
            " 'Graduate' 'Graduate' 'Graduate' 'Graduate' '10th Pass' 'Graduate'\n",
            " 'Post Graduate' 'Graduate' '10th Pass' 'Graduate' 'Graduate' 'Graduate'\n",
            " 'Post Graduate' 'Graduate' 'Graduate' 'Post Graduate' 'Graduate'\n",
            " '12th Pass' 'Graduate' 'Graduate' 'Graduate' 'Graduate'\n",
            " 'Graduate Professional' 'Graduate' 'Post Graduate' 'Graduate' 'Graduate'\n",
            " 'Post Graduate' 'Graduate' 'Graduate' 'Post Graduate'\n",
            " 'Graduate Professional' 'Post Graduate' 'Post Graduate' 'Post Graduate'\n",
            " 'Graduate' 'Graduate' 'Graduate' 'Post Graduate' 'Graduate'\n",
            " 'Post Graduate' 'Graduate' 'Graduate' 'Graduate' 'Graduate'\n",
            " 'Graduate Professional' '12th Pass' 'Graduate' 'Post Graduate' 'Graduate'\n",
            " 'Graduate' 'Graduate' '12th Pass' 'Post Graduate' '12th Pass'\n",
            " 'Post Graduate' 'Graduate' 'Post Graduate' 'Graduate Professional'\n",
            " 'Graduate' 'Graduate' 'Post Graduate' '12th Pass' 'Post Graduate'\n",
            " 'Graduate' '12th Pass' 'Graduate' 'Post Graduate' '12th Pass'\n",
            " 'Post Graduate' '10th Pass' 'Graduate' '12th Pass' 'Graduate'\n",
            " 'Post Graduate' '12th Pass' 'Post Graduate' 'Graduate' 'Post Graduate'\n",
            " 'Graduate' 'Graduate' 'Graduate' 'Post Graduate' 'Graduate'\n",
            " 'Post Graduate' 'Post Graduate' 'Post Graduate' 'Graduate' 'Graduate'\n",
            " 'Graduate' 'Graduate' '10th Pass' 'Graduate Professional' 'Post Graduate'\n",
            " 'Graduate Professional' 'Post Graduate' 'Graduate' 'Post Graduate'\n",
            " '12th Pass' 'Graduate' 'Post Graduate' 'Graduate' 'Graduate' '12th Pass'\n",
            " 'Post Graduate' 'Post Graduate' 'Graduate' '12th Pass' 'Graduate'\n",
            " 'Post Graduate' 'Post Graduate' 'Graduate' 'Post Graduate' 'Graduate'\n",
            " 'Graduate' 'Graduate' 'Post Graduate' 'Post Graduate' 'Graduate'\n",
            " 'Graduate' 'Graduate' 'Post Graduate' 'Graduate' 'Graduate Professional'\n",
            " 'Post Graduate' 'Graduate Professional' 'Post Graduate' 'Graduate'\n",
            " '12th Pass' 'Graduate Professional' 'Graduate' 'Graduate' 'Graduate'\n",
            " 'Graduate' 'Post Graduate' '10th Pass' 'Post Graduate' 'Post Graduate'\n",
            " 'Graduate' 'Graduate' 'Post Graduate' 'Post Graduate' 'Post Graduate'\n",
            " '10th Pass' 'Graduate Professional' 'Graduate Professional'\n",
            " 'Post Graduate' '12th Pass' 'Post Graduate' 'Post Graduate'\n",
            " 'Post Graduate' 'Graduate' '12th Pass' 'Post Graduate' 'Post Graduate'\n",
            " 'Graduate' '10th Pass' '12th Pass']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC-cvVGLDddz",
        "outputId": "7712df26-6f12-47f2-f96a-c3d1b2776dfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n",
            "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Step 1: Data Preprocessing\n",
        "data = pd.read_csv('train.csv')\n",
        "data1 = pd.read_csv('test.csv')\n",
        "data.drop(columns=['Candidate','Constituency ∇'], inplace=True)\n",
        "data1.drop(columns=['Candidate','Constituency ∇'], inplace=True)\n",
        "\n",
        "def convert_to_lakhs(value):\n",
        "    value = str(value)\n",
        "    if value == \"0\":\n",
        "        return 0\n",
        "    elif 'Crore+' in value:\n",
        "        number, unit = value.split()\n",
        "        number = float(number.replace(\",\", \"\"))\n",
        "        return int(number * 100)\n",
        "    elif 'Lac+' in value:\n",
        "        number, unit = value.split()\n",
        "        number = float(number.replace(\",\", \"\"))\n",
        "        return int(number)\n",
        "    elif 'Thou+' in value:\n",
        "        number, unit = value.split()\n",
        "        number = float(number.replace(\",\", \"\"))\n",
        "        return int(number / 100)\n",
        "    elif 'Hund+' in value:\n",
        "        number, unit = value.split()\n",
        "        number = float(number.replace(\",\", \"\"))\n",
        "        return int(number / 1000)\n",
        "    else:\n",
        "        return int(value)\n",
        "\n",
        "data[\"Total Assets\"] = data[\"Total Assets\"].apply(convert_to_lakhs)\n",
        "data[\"Liabilities\"] = data[\"Liabilities\"].apply(convert_to_lakhs)\n",
        "data1[\"Total Assets\"] = data1[\"Total Assets\"].apply(convert_to_lakhs)\n",
        "data1[\"Liabilities\"] = data1[\"Liabilities\"].apply(convert_to_lakhs)\n",
        "\n",
        "# Perform label encoding for Education column\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "data['Education'] = label_encoder.fit_transform(data['Education'])\n",
        "\n",
        "# data['Education'] = data['Education'].astype('category').cat.codes\n",
        "\n",
        "data = pd.get_dummies(data, columns=['Party','state'])\n",
        "data1 = pd.get_dummies(data1, columns=['Party','state'])\n",
        "\n",
        "X = data.drop(columns=['Education'])\n",
        "y = data['Education']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "data1 = scaler.transform(data1)\n",
        "\n",
        "# n_components = 30  # Specify the number of principal components\n",
        "# pca = PCA(n_components=n_components)\n",
        "# X_train = pca.fit_transform(X_train)\n",
        "# X_test = pca.transform(X_test)\n",
        "\n",
        "# Step 2: Training the Random Forest Classifier\n",
        "rf_classifier = RandomForestClassifier(n_estimators=85,\n",
        "                                        criterion='gini',\n",
        "                                        max_depth=30,\n",
        "                                        min_samples_split=2,\n",
        "                                        min_samples_leaf=1,\n",
        "                                        min_weight_fraction_leaf=0.0,\n",
        "                                        max_features='auto',\n",
        "                                        max_leaf_nodes=None,\n",
        "                                        min_impurity_decrease=0.0,\n",
        "                                        # min_impurity_split=None,\n",
        "                                        bootstrap=True,\n",
        "                                        oob_score=False,\n",
        "                                        n_jobs=None,\n",
        "                                        random_state=42,\n",
        "                                        verbose=1,\n",
        "                                        warm_start=False,\n",
        "                                        class_weight=None,\n",
        "                                        ccp_alpha=0.0,\n",
        "                                        max_samples=None)\n",
        "rf_classifier.fit(X, y)\n",
        "\n",
        "# Step 3: Model Evaluation\n",
        "y_pred = rf_classifier.predict(data1)\n",
        "# f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "# print(\"F1 Score:\", f1)\n",
        "y_pred = label_encoder.inverse_transform(y_pred)\n",
        "# Step 4: Data Visualization - Plotting code goes here\n",
        "\n",
        "# Step 5: Generate LaTeX Report - Details about the model, hyperparameters, evaluation metrics, and data visualization results.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred = pd.DataFrame(y_pred, columns=[\"Education\"])\n",
        "df_pred.to_csv('submission.csv', index_label='ID')"
      ],
      "metadata": {
        "id": "rQndNAXTEEMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "E7cAwZtdHEbS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47d4d0c6-be01-4192-ed10-cbe457583f3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['12th Pass', 'Graduate Professional', 'Graduate', ...,\n",
              "       'Post Graduate', 'Graduate Professional', '12th Pass'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pCig1cxeKEd9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}