{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# # from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.metrics import f1_score\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.datasets import load_iris\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# # Step 1: Data Preprocessing\n",
        "# data = pd.read_csv('train.csv')\n",
        "# # data1 = pd.read_csv('test.csv')\n",
        "# data.drop(columns=['Candidate','Constituency ∇'], inplace=True)\n",
        "# # data1.drop(columns=['Candidate','Constituency ∇'], inplace=True)\n",
        "\n",
        "# def convert_to_lakhs(value):\n",
        "#     value = str(value)\n",
        "#     if value == \"0\":\n",
        "#         return 0\n",
        "#     elif 'Crore+' in value:\n",
        "#         number, unit = value.split()\n",
        "#         number = float(number.replace(\",\", \"\"))\n",
        "#         return int(number * 100)\n",
        "#     elif 'Lac+' in value:\n",
        "#         number, unit = value.split()\n",
        "#         number = float(number.replace(\",\", \"\"))\n",
        "#         return int(number)\n",
        "#     elif 'Thou+' in value:\n",
        "#         number, unit = value.split()\n",
        "#         number = float(number.replace(\",\", \"\"))\n",
        "#         return int(number / 100)\n",
        "#     elif 'Hund+' in value:\n",
        "#         number, unit = value.split()\n",
        "#         number = float(number.replace(\",\", \"\"))\n",
        "#         return int(number / 1000)\n",
        "#     else:\n",
        "#         return int(value)\n",
        "\n",
        "# data[\"Total Assets\"] = data[\"Total Assets\"].apply(convert_to_lakhs)\n",
        "# data[\"Liabilities\"] = data[\"Liabilities\"].apply(convert_to_lakhs)\n",
        "# # data1[\"Total Assets\"] = data1[\"Total Assets\"].apply(convert_to_lakhs)\n",
        "# # data1[\"Liabilities\"] = data1[\"Liabilities\"].apply(convert_to_lakhs)\n",
        "\n",
        "# # Perform label encoding for Education column\n",
        "\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# # Encode the target variable\n",
        "# label_encoder = LabelEncoder()\n",
        "# data['Education'] = label_encoder.fit_transform(data['Education'])\n",
        "\n",
        "# # data['Education'] = data['Education'].astype('category').cat.codes\n",
        "\n",
        "# data = pd.get_dummies(data, columns=['Party','state'])\n",
        "# # data1 = pd.get_dummies(data1, columns=['Party','state'])\n",
        "\n",
        "# X = data.drop(columns=['Education'])\n",
        "# y = data['Education']\n",
        "\n",
        "# # Split data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# param_grid = {\n",
        "#     'n_neighbors': [3, 5, 7, 6],      # Number of neighbors\n",
        "#     'weights': ['uniform', 'distance'],  # Weight function used in prediction\n",
        "#     'p': [1, 2],                    # Power parameter for Minkowski distance\n",
        "#     'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algorithm used to compute nearest neighbors\n",
        "#     'leaf_size': [10, 20, 30],  # Leaf size passed to BallTree or KDTree\n",
        "#     'metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski']  # Distance metric to use for the tree\n",
        "# }\n",
        "\n",
        "# # Initialize KNN classifier\n",
        "# knn_classifier = KNeighborsClassifier()\n",
        "\n",
        "# # Initialize GridSearchCV\n",
        "# grid_search = GridSearchCV(estimator=knn_classifier, param_grid=param_grid, cv=5)\n",
        "\n",
        "# # Fit the GridSearchCV to the training data\n",
        "# grid_search.fit(X_train, y_train)\n",
        "\n",
        "# # Print the best parameters found by GridSearchCV\n",
        "# print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# # Predict on the test set using the best model\n",
        "# best_knn_classifier = grid_search.best_estimator_\n",
        "# y_pred = best_knn_classifier.predict(X_test)\n",
        "\n",
        "# # Calculate accuracy\n",
        "# # accuracy = accuracy_score(y_test, y_pred)\n",
        "# # print(\"Accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "# # # Step 2: Training the Random Forest Classifier\n",
        "# # rf_classifier = RandomForestClassifier(n_estimators=90,\n",
        "# #                                         criterion='gini',\n",
        "# #                                         max_depth=30,\n",
        "# #                                         min_samples_split=2,\n",
        "# #                                         min_samples_leaf=1,\n",
        "# #                                         min_weight_fraction_leaf=0.0,\n",
        "# #                                         max_features='auto',\n",
        "# #                                         max_leaf_nodes=None,\n",
        "# #                                         min_impurity_decrease=0.0,\n",
        "# #                                         # min_impurity_split=None,\n",
        "# #                                         bootstrap=True,\n",
        "# #                                         oob_score=False,\n",
        "# #                                         n_jobs=None,\n",
        "# #                                         random_state=42,\n",
        "# #                                         verbose=1,\n",
        "# #                                         warm_start=False,\n",
        "# #                                         class_weight=None,\n",
        "# #                                         ccp_alpha=0.0,\n",
        "# #                                         max_samples=None)\n",
        "# # rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "# # # Step 3: Model Evaluation\n",
        "# # y_pred = rf_classifier.predict(X_test)\n",
        "\n",
        "# f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "# print(\"F1 Score:\", f1)\n",
        "# # y_pred = label_encoder.inverse_transform(y_pred)\n",
        "# # Step 4: Data Visualization - Plotting code goes here\n",
        "\n",
        "# # Step 5: Generate LaTeX Report - Details about the model, hyperparameters, evaluation metrics, and data visualization results.\n"
      ],
      "metadata": {
        "id": "kZMt6lreQSOU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c116c55-4df6-4308-fc91-52bde8d0fcfa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'algorithm': 'ball_tree', 'leaf_size': 10, 'metric': 'chebyshev', 'n_neighbors': 6, 'p': 1, 'weights': 'distance'}\n",
            "F1 Score: 0.15946395545574543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Step 1: Data Preprocessing\n",
        "data = pd.read_csv('train.csv')\n",
        "data1 = pd.read_csv('test.csv')\n",
        "data.drop(columns=['Candidate','Constituency ∇'], inplace=True)\n",
        "data1.drop(columns=['Candidate','Constituency ∇'], inplace=True)\n",
        "\n",
        "def convert_to_lakhs(value):\n",
        "    value = str(value)\n",
        "    if value == \"0\":\n",
        "        return 0\n",
        "    elif 'Crore+' in value:\n",
        "        number, unit = value.split()\n",
        "        number = float(number.replace(\",\", \"\"))\n",
        "        return int(number * 100)\n",
        "    elif 'Lac+' in value:\n",
        "        number, unit = value.split()\n",
        "        number = float(number.replace(\",\", \"\"))\n",
        "        return int(number)\n",
        "    elif 'Thou+' in value:\n",
        "        number, unit = value.split()\n",
        "        number = float(number.replace(\",\", \"\"))\n",
        "        return int(number / 100)\n",
        "    elif 'Hund+' in value:\n",
        "        number, unit = value.split()\n",
        "        number = float(number.replace(\",\", \"\"))\n",
        "        return int(number / 1000)\n",
        "    else:\n",
        "        return int(value)\n",
        "\n",
        "data[\"Total Assets\"] = data[\"Total Assets\"].apply(convert_to_lakhs)\n",
        "data[\"Liabilities\"] = data[\"Liabilities\"].apply(convert_to_lakhs)\n",
        "data1[\"Total Assets\"] = data1[\"Total Assets\"].apply(convert_to_lakhs)\n",
        "data1[\"Liabilities\"] = data1[\"Liabilities\"].apply(convert_to_lakhs)\n",
        "\n",
        "# Perform label encoding for Education column\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "data['Education'] = label_encoder.fit_transform(data['Education'])\n",
        "\n",
        "# data['Education'] = data['Education'].astype('category').cat.codes\n",
        "\n",
        "data = pd.get_dummies(data, columns=['Party','state'])\n",
        "data1 = pd.get_dummies(data1, columns=['Party','state'])\n",
        "\n",
        "X = data.drop(columns=['Education'])\n",
        "y = data['Education']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 6],      # Number of neighbors\n",
        "    'weights': ['uniform', 'distance'],  # Weight function used in prediction\n",
        "    'p': [1, 2],                    # Power parameter for Minkowski distance\n",
        "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algorithm used to compute nearest neighbors\n",
        "    'leaf_size': [10, 20, 30],  # Leaf size passed to BallTree or KDTree\n",
        "    'metric': ['euclidean', 'manhattan', 'chebyshev', 'minkowski']  # Distance metric to use for the tree\n",
        "}\n",
        "\n",
        "# Initialize KNN classifier\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=knn_classifier, param_grid=param_grid, cv=5)\n",
        "\n",
        "# Fit the GridSearchCV to the training data\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "# Print the best parameters found by GridSearchCV\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Predict on the test set using the best model\n",
        "best_knn_classifier = grid_search.best_estimator_\n",
        "y_pred = best_knn_classifier.predict(data1)\n",
        "\n",
        "# # Step 2: Training the Random Forest Classifier\n",
        "# rf_classifier = RandomForestClassifier(n_estimators=90,\n",
        "#                                         criterion='gini',\n",
        "#                                         max_depth=30,\n",
        "#                                         min_samples_split=2,\n",
        "#                                         min_samples_leaf=1,\n",
        "#                                         min_weight_fraction_leaf=0.0,\n",
        "#                                         max_features='auto',\n",
        "#                                         max_leaf_nodes=None,\n",
        "#                                         min_impurity_decrease=0.0,\n",
        "#                                         # min_impurity_split=None,\n",
        "#                                         bootstrap=True,\n",
        "#                                         oob_score=False,\n",
        "#                                         n_jobs=None,\n",
        "#                                         random_state=42,\n",
        "#                                         verbose=1,\n",
        "#                                         warm_start=False,\n",
        "#                                         class_weight=None,\n",
        "#                                         ccp_alpha=0.0,\n",
        "#                                         max_samples=None)\n",
        "# rf_classifier.fit(X, y)\n",
        "\n",
        "# # Step 3: Model Evaluation\n",
        "# y_pred = rf_classifier.predict(data1)\n",
        "# # f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "# # print(\"F1 Score:\", f1)\n",
        "y_pred = label_encoder.inverse_transform(y_pred)\n",
        "\n",
        "\n",
        "# Step 4: Data Visualization - Plotting code goes here\n",
        "\n",
        "# Step 5: Generate LaTeX Report - Details about the model, hyperparameters, evaluation metrics, and data visualization results.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmcwSNukx0uX",
        "outputId": "c8ac23d5-15f9-4b36-fe46-553611eef5f0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'algorithm': 'auto', 'leaf_size': 10, 'metric': 'chebyshev', 'n_neighbors': 6, 'p': 1, 'weights': 'uniform'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_pred = pd.DataFrame(y_pred, columns=[\"Education\"])\n",
        "df_pred.to_csv('submission.csv', index_label='ID')"
      ],
      "metadata": {
        "id": "7NXczEna63i8"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RYZ3FO868Xzf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}